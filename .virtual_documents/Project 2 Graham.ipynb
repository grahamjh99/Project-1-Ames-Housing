import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import RidgeCV, Ridge
from sklearn.preprocessing import StandardScaler
from sklearn import metrics








df = pd.read_csv('./datasets/train.csv')
test = pd.read_csv('./datasets/test.csv')
df.head()


df.set_index('Id', inplace = True)
test.set_index('Id', inplace = True)


df.columns


# supress output for easier scrolling
df.info();


df.isnull().sum()








df[df['Garage Area'].isnull()]


df[(df['Garage Area'].isnull()) & (df['Garage Cars'].isnull())][['Garage Area', 'Garage Cars', 'Garage Qual']]


df[df['Garage Area'] == 0]


df[['Garage Area', 'Garage Cars']] = df[['Garage Area', 'Garage Cars']].replace({np.nan: 0})
test[['Garage Area', 'Garage Cars']] = test[['Garage Area', 'Garage Cars']].replace({np.nan: 0})
df[(df['Garage Area']== 0) & (df['Garage Cars'] == 0)][['Garage Area', 'Garage Cars', 'Garage Qual']]








df[(df['Mas Vnr Type'].isnull()) & (df['Mas Vnr Area'].isnull())][['Mas Vnr Area', 'Mas Vnr Type']]


df['Mas Vnr Area'] = df[['Mas Vnr Area']].replace({np.nan: 0})
test['Mas Vnr Area'] = test[['Mas Vnr Area']].replace({np.nan: 0})





df[(df['BsmtFin SF 1'].isnull()) & (df['BsmtFin Type 1'].isnull())][['BsmtFin SF 1', 'BsmtFin Type 1']]


df[['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF','Bsmt Full Bath','Bsmt Half Bath']] = df[['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF','Bsmt Full Bath','Bsmt Half Bath']].replace({np.nan: 0})
test[['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF','Bsmt Full Bath','Bsmt Half Bath']] = test[['BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF','Bsmt Full Bath','Bsmt Half Bath']].replace({np.nan: 0})





df['totalsf'] = df['Pool Area']+df['Wood Deck SF']+ df['Open Porch SF']+df['Lot Area']+df['Enclosed Porch']+df['3Ssn Porch']+ df['Screen Porch']+df['Total Bsmt SF']+df['Gr Liv Area']+df['Garage Area']
test['totalsf'] = test['Pool Area']+test['Wood Deck SF']+ test['Open Porch SF']+test['Lot Area']+test['Enclosed Porch']+test['3Ssn Porch']+ test['Screen Porch']+test['Total Bsmt SF']+test['Gr Liv Area']+test['Garage Area']





sns.boxplot(x='House Style', y='SalePrice', data=df)
plt.xticks(rotation=45);


sns.boxplot(x='Bldg Type', y='SalePrice', data=df)
plt.xticks(rotation=45);





# df_numeric = df[['Mo Sold','Yr Sold','SalePrice','Screen Porch','Pool Area','3Ssn Porch',
#                  'Enclosed Porch','Open Porch SF','Wood Deck SF','Id','PID','MS SubClass',
#                  'Lot Area','Overall Qual','Overall Cond','Year Built','Year Remod/Add',
#                 'Mas Vnr Area','1st Flr SF','2nd Flr SF','Low Qual Fin SF','BsmtFin SF 1',
#                 'BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF','Gr Liv Area','Full Bath','Half Bath',
#                 'Kitchen AbvGr','Bedroom AbvGr','TotRms AbvGrd','Fireplaces','Garage Area','Garage Cars','Garage Yr Blt','Bsmt Half Bath','Bsmt Full Bath']]

# Drop non-numeric columns
df_numeric = df.select_dtypes(include=['int', 'float'])

# Create the heatmap
plt.figure(figsize=(3, 10))
sns.heatmap(df_numeric.corr()[['SalePrice']].sort_values(by='SalePrice',ascending = False), 
            annot=True,
            cmap='viridis');





# Drop the original column and join the dummies
df = pd.get_dummies(df, 
                    columns = ['MS SubClass'],
                    prefix = 'mssubclass',
                    dtype = int)
df.columns


plt.hist(df['Overall Cond'],
        bins = 40,
        edgecolor = 'black');








df['Lot Frontage'] = df[['Lot Frontage']].replace({np.nan: 0})
test['Lot Frontage'] = test[['Lot Frontage']].replace({np.nan: 0})


# Drop non-numeric columns
df_numeric = df.select_dtypes(include=['int', 'float'])

# Create the heatmap
plt.figure(figsize=(3, 15))
sns.heatmap(df_numeric.corr()[['SalePrice']].sort_values(by='SalePrice',ascending = False), 
            annot=True,
            cmap='viridis');








plt.hist(df['SalePrice'],
        bins = 40,
        edgecolor = 'black')
plt.title('Ames Iowa House Sale Prices')
plt.xlabel('Sale Price')
plt.ylabel('Frequency');

plt.savefig('./Graphs/Ames Iowa House Sale Prices')


np.mean(df['SalePrice'])


# supress output for easier scrolling
df.info();


test.info();





# fixing MS SubClass to match training data
test = pd.get_dummies(test, 
                    columns = ['MS SubClass'],
                    prefix = 'mssubclass',
                    dtype = int)
test.columns








X = df[['PID', 'Overall Qual', 'Gr Liv Area', 'Year Built', 'Garage Area', 'Total Bsmt SF', 'Year Remod/Add', 'TotRms AbvGrd', 'Lot Area','mssubclass_30','BsmtFin SF 1']]
y = df['SalePrice']


X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42)
lr = LinearRegression()
lr.fit(X_train,y_train)

lr.score(X_train,y_train)


lr.score(X_test,y_test)





y_pred = lr.predict(X_test)
residuals = y_test - y_pred

# Create residual plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Sale Price')
plt.ylabel('Residuals')
plt.title('Residual Plot');


metrics.mean_squared_error(y_test,y_pred)








lr.fit(X,y)


preds = lr.predict(test[['PID', 'Overall Qual', 'Gr Liv Area', 'Year Built', 'Garage Area', 'Total Bsmt SF', 'Year Remod/Add', 'TotRms AbvGrd', 'Lot Area','mssubclass_30','BsmtFin SF 1']])
predictions = test.copy()
predictions['SalePrice'] = preds
predictions = predictions[['SalePrice']]
predictions.head()





plt.hist(predictions['SalePrice'],
        bins = 40,
        edgecolor = 'black')






predictions.to_csv('./Predictions/only_numeric_predictions.csv')
# this got about a 30k score. While I have no clue what that means I'll assume that is bad since just the overall condition column got a 50k score











df[['Alley']] = df[['Alley']].replace({np.nan: 'None'})
test[['Alley']] = test[['Alley']].replace({np.nan: 'None'})





df[['Garage Type','Garage Finish']] = df[['Garage Type','Garage Finish']].replace({np.nan:'None'})
test[['Garage Type','Garage Finish']] = test[['Garage Type','Garage Finish']].replace({np.nan:'None'})





df['Mas Vnr Type'] = df['Mas Vnr Type'].replace({np.nan:'None'})
test['Mas Vnr Type'] = test['Mas Vnr Type'].replace({np.nan:'None'})





df[['BsmtFin Type 1','BsmtFin Type 2']] = df[['BsmtFin Type 1','BsmtFin Type 2']].replace({np.nan:'None'})
test[['BsmtFin Type 1','BsmtFin Type 2']] = test[['BsmtFin Type 1','BsmtFin Type 2']].replace({np.nan:'None'})





df['Misc Feature'] = df['Misc Feature'].replace({np.nan:'None'})
test['Misc Feature'] = test['Misc Feature'].replace({np.nan:'None'})





df['Bsmt Qual'] = df[['Bsmt Qual']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1,
                                               np.nan: 0})
test['Bsmt Qual'] = test[['Bsmt Qual']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1,
                                               np.nan: 0})





df['Bsmt Cond'] = df[['Bsmt Cond']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1,
                                               np.nan: 0})
test['Bsmt Cond'] = test[['Bsmt Cond']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1,
                                               np.nan: 0})





df[['Exter Qual','Exter Cond']] = df[['Exter Qual','Exter Cond']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1})
test[['Exter Qual','Exter Cond']] = test[['Exter Qual','Exter Cond']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1})





df['Bsmt Exposure'] = df[['Bsmt Exposure']].replace({
                                               'Gd':4,
                                               'Av':3,
                                               'Mn':2,
                                               'No':1,
                                               np.nan: 0})
test['Bsmt Exposure'] = test[['Bsmt Exposure']].replace({
                                               'Gd':4,
                                               'Av':3,
                                               'Mn':2,
                                               'No':1,
                                               np.nan: 0})





df[['Heating QC','Kitchen Qual']] = df[['Heating QC','Kitchen Qual']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1})
test[['Heating QC','Kitchen Qual']] = test[['Heating QC','Kitchen Qual']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1})





df[['Fireplace Qu','Garage Qual','Garage Cond']] = df[['Fireplace Qu','Garage Qual','Garage Cond']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1,
                                               np.nan: 0})
test[['Fireplace Qu','Garage Qual','Garage Cond']] = test[['Fireplace Qu','Garage Qual','Garage Cond']].replace({'Ex':5,
                                               'Gd':4,
                                               'TA':3,
                                               'Fa':2,
                                               'Po':1,
                                               np.nan: 0})





df['Pool QC'] = df[['Pool QC']].replace({'Ex':4,
                                               'Gd':3,
                                               'TA':2,
                                               'Fa':1,
                                               np.nan: 0})
test['Pool QC'] = test[['Pool QC']].replace({'Ex':4,
                                               'Gd':3,
                                               'TA':2,
                                               'Fa':1,
                                               np.nan: 0})





def make_dummies(df,test,column):
    df = pd.get_dummies(df, 
                        columns = [column],
                        prefix = column.strip(),
                        dtype = int)
    test = pd.get_dummies(test, 
                        columns=[column], 
                        prefix=column.strip(), 
                        dtype=int)

    return df, test





df, test = make_dummies(df,test,'MS Zoning')
df, test = make_dummies(df,test,'Street')
df, test = make_dummies(df,test,'Alley')
df, test = make_dummies(df,test,'Lot Shape')
df, test = make_dummies(df,test,'Land Contour')
df, test = make_dummies(df,test,'Lot Config')
df, test = make_dummies(df,test,'Land Slope')
df, test = make_dummies(df,test,'Neighborhood')
df, test = make_dummies(df,test,'Condition 1')
df, test = make_dummies(df,test,'Condition 2')
df, test = make_dummies(df,test,'Bldg Type')
df, test = make_dummies(df,test,'House Style')
df, test = make_dummies(df,test,'Roof Style')
df, test = make_dummies(df,test,'Roof Matl')
df, test = make_dummies(df,test,'Exterior 1st')
df, test = make_dummies(df,test,'Exterior 2nd')
df, test = make_dummies(df,test,'Mas Vnr Type')
df, test = make_dummies(df,test,'Foundation')
df, test = make_dummies(df,test,'BsmtFin Type 1')
df, test = make_dummies(df,test,'BsmtFin Type 2')
df, test = make_dummies(df,test,'Heating')
df, test = make_dummies(df,test,'Central Air')
df, test = make_dummies(df,test,'Electrical')
df, test = make_dummies(df,test,'Functional')
df, test = make_dummies(df,test,'Garage Type')
df, test = make_dummies(df,test,'Garage Finish')
df, test = make_dummies(df,test,'Paved Drive')
df, test = make_dummies(df,test,'Fence')
df, test = make_dummies(df,test,'Sale Type')
df, test = make_dummies(df,test,'Misc Feature')
df, test = make_dummies(df,test,'Utilities')





# comment out for easier scrolling
# plt.figure(figsize=(3, 55))
# sns.heatmap(df.corr()[['SalePrice']].sort_values(by='SalePrice',ascending = False), 
#             annot=True,
#             cmap='viridis');


# supress output for easier scrolling
df.info(verbose = True,
       show_counts = True);





correlations = df.corr()['SalePrice']
selected_columns = correlations[(correlations >0.2)|(correlations <-0.2)].index
selected_columns = selected_columns.drop(['SalePrice', 'Garage Yr Blt'])
X = df[selected_columns]
y = df['SalePrice']
X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42)
lr = LinearRegression()
lr.fit(X_train,y_train)

lr.score(X_train,y_train)


lr.score(X_test,y_test)


y_pred = lr.predict(X_test)
residuals = y_test - y_pred

# Create residual plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Sale Price')
plt.ylabel('Residuals')
plt.title('Residual Plot');


metrics.mean_squared_error(y_test,y_pred)


lr.fit(X,y)
preds = lr.predict(test[selected_columns])
predictions = test.copy()
predictions['SalePrice'] = preds
predictions = predictions[['SalePrice']]
predictions.head()


plt.hist(predictions['SalePrice'],
        bins = 40,
        edgecolor = 'black');


predictions.to_csv('./Predictions/Full_data_predictions_1.csv')














# found out through an error that ['Neighborhood_GrnHill', 'Neighborhood_Landmrk'] are not in the test data at all so let's make those columns and fill them in with 0s
test[['Neighborhood_GrnHill', 'Neighborhood_Landmrk']] = 0


keywords = [
    'Garage', 'BsmtFin Type 1_GLQ', 'House Style', 'Overall', 'Exter Qual',
    'Year', 'Exter Cond', 'Porch', 'Deck', 'Bldg', 'Fireplace', 'Gr Liv Area',
    'Total Bsmt SF', 'Bsmt Exposure', 'Bsmt Qual', 'Neighborhood'
]
def filter_columns_train_test(df_train, df_test, keywords):
   
    # Find columns that contain any of the keywords
    filtered_columns = [
        col for col in df_train.columns 
        if any(keyword in col for keyword in keywords)]
    
    # Filter the train and test DataFrames
    df_train_filtered = df_train[filtered_columns]
    df_test_filtered = df_test[filtered_columns]

    # Ensure 'Id' remains as the index (do not reset the index)
    # This is from chatgpt 
    df_train_filtered.index = df_train.index
    df_test_filtered.index = df_test.index
    
    return df_train_filtered, df_test_filtered
df_train_filtered, df_test_filtered = filter_columns_train_test(df, test, keywords)





df_train_filtered['SalePrice'] = df['SalePrice']





df_train_filtered.drop(columns = 'Garage Yr Blt', inplace = True)
df_test_filtered.drop(columns = 'Garage Yr Blt', inplace = True)


df_train_filtered.columns = df_train_filtered.columns.str.lower().str.replace(' ','_')
df_test_filtered.columns = df_test_filtered.columns.str.lower().str.replace(' ','_')





df_train_filtered['has_porch'] = df_train_filtered['enclosed_porch'] + df_train_filtered['3ssn_porch'] + df_train_filtered['screen_porch']
df_train_filtered['garage_capacity'] = df_train_filtered['garage_area'] * df_train_filtered['garage_cars']
df_train_filtered['age'] = 2010 - df_train_filtered['year_built']
df_train_filtered['years_since_remod'] = df_train_filtered['year_remod/add'] - df_train_filtered['year_built']
df_train_filtered['total_quality'] = df_train_filtered['overall_qual'] * df_train_filtered['overall_cond']

df_test_filtered['has_porch'] = df_test_filtered['enclosed_porch'] + df_test_filtered['3ssn_porch'] + df_test_filtered['screen_porch']
df_test_filtered['garage_capacity'] = df_test_filtered['garage_area'] * df_test_filtered['garage_cars']
df_test_filtered['age'] = 2010 - df_test_filtered['year_built']
df_test_filtered['years_since_remod'] = df_test_filtered['year_remod/add'] - df_test_filtered['year_built']
df_test_filtered['total_quality'] = df_test_filtered['overall_qual'] * df_test_filtered['overall_cond']


df_train_filtered.info();





plt.figure(figsize=(3, 5))
corr_matrix = df_train_filtered[['has_porch', 'garage_capacity', 'saleprice','age', 'total_quality','years_since_remod']].corr()
sns.heatmap(corr_matrix.corr()[['saleprice']].sort_values(by='saleprice',ascending = False), 
            annot=True,
            cmap='viridis');





columns_to_drop = [
    'enclosed_porch', '3ssn_porch', 'screen_porch',  # since I have have has_porch
    'garage_area', 'garage_cars',  # since I have have garage_capacity
    'year_built', # since I have age
    'overall_qual', 'overall_cond', # since I have total quality
    # Drop one category from each categorical variable to avoid dummy trap
    'bldg_type_1fam',  
    'house_style_1story',
    'garage_type_2types',
]

df_train_filtered = df_train_filtered.drop(columns=columns_to_drop)
df_test_filtered = df_test_filtered.drop(columns=columns_to_drop)





X = df_train_filtered.drop(columns = 'saleprice')
y = df_train_filtered['saleprice']

X['log_gr_liv_area'] = np.log(X['gr_liv_area'])
X['log_total_bsmt_sf'] = np.log(X['total_bsmt_sf'] + 1)  # +1 to handle zeros
X['wood_deck_sf'] = np.log(X['wood_deck_sf'] + 1)  # +1 to handle zeros
X['open_porch_sf'] = np.log(X['open_porch_sf'] + 1)  # +1 to handle zeros


df_test_filtered['log_gr_liv_area'] = np.log(df_test_filtered['gr_liv_area'])
df_test_filtered['log_total_bsmt_sf'] = np.log(df_test_filtered['total_bsmt_sf'] + 1)  # +1 to handle zeros
df_test_filtered['wood_deck_sf'] = np.log(df_test_filtered['wood_deck_sf'] + 1)  # +1 to handle zeros
df_test_filtered['open_porch_sf'] = np.log(df_test_filtered['open_porch_sf'] + 1)  # +1 to handle zeros

y = np.log(df_train_filtered['saleprice']) # transforming prices into a percent

X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42)
lr = LinearRegression()
lr.fit(X_train,y_train)

print(lr.score(X_train,y_train))
print(lr.score(X_test,y_test))


y_pred = lr.predict(X_test)
residuals = y_test - y_pred

# Create residual plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Sale Price')
plt.ylabel('Residuals')
plt.title('Residual Plot');


metrics.mean_squared_error(y_test,y_pred)


# Find the outlier
outlier_index = residuals[residuals <= -1.5].index

# Display details of this data point
outlier_data = X_test.loc[outlier_index]
outlier_target = y_test.loc[outlier_index]
outlier_pred = y_pred[outlier_index]
outlier_residuals = residuals[outlier_index]

print("Outlier Index:", outlier_index)
print("Outlier Feature Values:\n", outlier_data)
print("Actual Log Sale Price:", outlier_target.values)
print("Predicted Log Sale Price:", outlier_pred)
print("Residuals:", outlier_residuals)


lr.fit(X,y)
preds = lr.predict(df_test_filtered)
predictions = df_test_filtered.copy()
# change those logs back to actual housing prices
predictions['saleprice'] = np.exp(preds)
predictions = predictions[['saleprice']]
predictions.head()


plt.hist(predictions['saleprice'],
        bins = 40,
        edgecolor = 'black');
plt.title('Histogram of Predicted Housing Prices')
plt.xlabel('Predicted Housing Prices')
plt.ylabel('Frequency');


np.mean(predictions['saleprice'])


predictions.to_csv('./Predictions/filtered_data_predictions_2.csv')
# there was a filtered predictions 1 but I accidentally dropped garage condition and quality instead of garage area and garage cars so I needed to fix that. 
# I also made the age column by subtracting from 2024. I do not think this matters overly much but it should be from when the housing data was collected which, was 2010











df_train_filtered['house_sf'] = ((df_train_filtered['gr_liv_area'] * df_train_filtered['house_style_1.5fin'])+
                                (df_train_filtered['gr_liv_area'] *df['House Style_1Story']) + 
                                (df_train_filtered['gr_liv_area']* df_train_filtered['house_style_1.5unf']) + 
                                (df_train_filtered['gr_liv_area']* df_train_filtered['house_style_2.5fin']) +
                                (df_train_filtered['gr_liv_area']* df_train_filtered['house_style_2.5unf']) +
                                (df_train_filtered['gr_liv_area']* df_train_filtered['house_style_2story']) +
                                (df_train_filtered['gr_liv_area']* df_train_filtered['house_style_sfoyer']) + 
                                (df_train_filtered['gr_liv_area']* df_train_filtered['house_style_slvl']))
df_test_filtered['house_sf'] = ((df_test_filtered['gr_liv_area'] * df_test_filtered['house_style_1.5fin'])+
                                (df_test_filtered['gr_liv_area'] * test['House Style_1Story']) + 
                                (df_test_filtered['gr_liv_area']* df_test_filtered['house_style_1.5unf']) + 
                                (df_test_filtered['gr_liv_area']* df_test_filtered['house_style_2.5fin']) +
                                (df_test_filtered['gr_liv_area']* df_test_filtered['house_style_2.5unf']) +
                                (df_test_filtered['gr_liv_area']* df_test_filtered['house_style_2story']) +
                                (df_test_filtered['gr_liv_area']* df_test_filtered['house_style_sfoyer']) + 
                                (df_test_filtered['gr_liv_area']* df_test_filtered['house_style_slvl']))

# overwrite from previous model because the math that was being done was how many years it took to remodel the house after being built which does not mean much
df_train_filtered['years_since_remod'] = 2010 - df_train_filtered['year_remod/add']
df_test_filtered['years_since_remod'] = 2010 - df_test_filtered['year_remod/add']

df_train_filtered['total_garage_quality'] = df_train_filtered['garage_cond'] * df_train_filtered['garage_qual']
df_test_filtered['total_garage_quality'] = df_test_filtered['garage_cond'] * df_test_filtered['garage_qual']

df_train_filtered['total_exter_quality'] = df_train_filtered['exter_cond'] * df_train_filtered['exter_qual']
df_test_filtered['total_exter_quality'] = df_test_filtered['exter_cond'] * df_test_filtered['exter_qual']

df_train_filtered['total_basement_quality'] = df_train_filtered['bsmt_qual'] * df['Bsmt Cond']
df_test_filtered['total_basement_quality'] = df_test_filtered['bsmt_qual'] * test['Bsmt Cond']

columns_to_drop = [
    'gr_liv_area', # since I have house_sf
    'year_remod/add', # since I have years_since_remod
    'garage_cond', 'garage_qual', # since I have total_garage_quality
    'exter_qual','exter_cond',# since I have total_exter_quality
    'house_style_1.5fin','house_style_2.5fin','house_style_2.5unf','house_style_2story','house_style_sfoyer','house_style_slvl','house_style_1.5unf',
    'bsmt_qual'] 

df_train_filtered = df_train_filtered.drop(columns=columns_to_drop)
df_test_filtered = df_test_filtered.drop(columns=columns_to_drop)

# These were made in the previous model and I need to take them out
df_test_filtered.drop(columns = 'log_gr_liv_area', inplace = True)
df_test_filtered.drop(columns = 'log_total_bsmt_sf', inplace = True)

df_train_filtered_dropped = df_train_filtered.drop(index=182,inplace= True)


X = df_train_filtered.drop(columns = 'saleprice')
y = df_train_filtered['saleprice']

X['house_sf'] = np.log(X['house_sf'] + 1)
X['total_bsmt_sf'] = np.log(X['total_bsmt_sf'] + 1)  # +1 to handle zeros
X['wood_deck_sf'] = np.log(X['wood_deck_sf'] + 1)  # +1 to handle zeros
X['open_porch_sf'] = np.log(X['open_porch_sf'] + 1)  # +1 to handle zeros
X['garage_capacity'] = np.log(X['garage_capacity'] + 1)

df_test_filtered['house_sf'] = np.log(df_test_filtered['house_sf'] + 1)
df_test_filtered['garage_capacity'] = np.log(df_test_filtered['garage_capacity'] + 1)
df_test_filtered['total_bsmt_sf'] = np.log(df_test_filtered['total_bsmt_sf'] + 1)  # +1 to handle zeros
df_test_filtered['wood_deck_sf'] = np.log(df_test_filtered['wood_deck_sf'] + 1)  # +1 to handle zeros
df_test_filtered['open_porch_sf'] = np.log(df_test_filtered['open_porch_sf'] + 1)  # +1 to handle zeros

y = np.log(df_train_filtered['saleprice']) # transforming prices into a percent

X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42)
lr = LinearRegression()
lr.fit(X_train,y_train)

print(lr.score(X_train,y_train))
print(lr.score(X_test,y_test))


y_test = np.exp(y_test)

y_pred = lr.predict(X_test)
y_pred = np.exp(y_pred)
residuals = y_test - y_pred

# Create residual plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Sale Price')
plt.ylabel('Prediction Discrepancy')
plt.title('Residual Plot');

plt.savefig('./Graphs/Residual Plot')


# Scatter plot of Actual vs. Predicted Sale Prices with adjusted limits
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)

# Calc min max values for actual and predicted for the line
min_val = min(y_test.min(), y_pred.min())
max_val = max(y_test.max(), y_pred.max())

# Make the 45 degree line
plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label="45-degree line")

plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')
plt.title('Actual vs. Predicted Sale Prices in USD');

plt.savefig('./Graphs/Actual vs Predicted Sale Prices in USD')


# Select a few random sample indices from the test set
sample_indices = X_test.sample(10, random_state=42).index

# Extract sample data for actual values and features
sample_X = X_test.loc[sample_indices]
sample_y_actual = y_test.loc[sample_indices]

# Predict sale prices for these samples and convert back to original scale
sample_y_pred_log = lr.predict(sample_X)
sample_y_pred = np.exp(sample_y_pred_log)

# Calculate percentage error
percentage_error = ((sample_y_pred - sample_y_actual) / sample_y_actual) * 100

# Create a DataFrame to display the results
sample_results = pd.DataFrame({
    'House Square Footage': np.exp(sample_X['house_sf']),  # Convert log-transformed features if needed
    'Garage Capacity': np.exp(sample_X['garage_capacity']),
    'Total Basement SF': np.exp(sample_X['total_bsmt_sf']),
    'Age of House': sample_X['age'],
    'Years since Remodel': sample_X['years_since_remod'],
    'Actual Sale Price': sample_y_actual,
    'Predicted Sale Price': sample_y_pred,
    'Percentage Error': percentage_error
})

# Display the table
print(sample_results)


coefficients = lr.coef_
feature_names = X_train.columns

coef_dict = {feature: coef for feature, coef in zip(feature_names, coefficients)}

coef_df = pd.DataFrame(coef_dict.items(), columns=['Feature', 'Coefficient'])
coef_df = coef_df.sort_values(by='Coefficient', ascending=False)
print(coef_df)


# Get top 5 features with the largest positive coefficients
top_positive = coef_df.nlargest(5, 'Coefficient')

# Get top 5 features with the largest negative coefficients
top_negative = coef_df.nsmallest(5, 'Coefficient')
top_positive['Exponentiated Coefficient'] = np.exp(top_positive['Coefficient'])
top_negative['Exponentiated Coefficient'] = np.exp(top_negative['Coefficient'])


selected_features = pd.concat([top_positive, top_negative])
selected_features['Feature'] = selected_features['Feature'].replace({
    'neighborhood_grnhill': 'Green Hills',
    'house_sf': 'House sq ft',
    'garage_finish_none': 'No Garage',
    'neighborhood_stonebr': 'Stone Brook',
    'neighborhood_nridght': 'Northridge Heights',
    'garage_finish_unf': 'Unfinished Garage',
    'garage_finish_rfn': 'Rough Finished Garage',
    'bldg_type_twnhs': 'Townhouse',
    'garage_type_none': 'No Garage',
    'neighborhood_idotrr': 'Iowa DOT and Rail Road'
})

# Create color mapping
colors = []

# Store the original feature names before replacement for comparison
original_top_positive = top_positive.index
original_top_negative = top_negative.index

# Chatgpt helped with doing the colors in the way shown
for name in selected_features.index:
    if name in original_top_positive:
        colors.append('#0077BB')  # blue is positive, colors from chatgpt
    elif name in original_top_negative:
        colors.append('#EE7733')  # orange is negative


# Create the bar plot
plt.figure(figsize=(10, 6))
plt.barh(selected_features['Feature'],
         selected_features['Exponentiated Coefficient'],
         color=colors)

# Set plot title and labels
plt.title('Top 5 Most and Least Influential Features')
plt.xlabel('Exponentiated Coefficients')
plt.ylabel('Features')
plt.tight_layout();

# Save the plot
plt.savefig('./Graphs/Top 5 Most and Least Influential Features')


metrics.mean_squared_error(y_test,y_pred)


lr.fit(X,y)
preds = lr.predict(df_test_filtered)
predictions = df_test_filtered.copy()
# change those logs back to actual housing prices
predictions['saleprice'] = np.exp(preds)
predictions = predictions[['saleprice']]
predictions.head()


plt.hist(predictions['saleprice'],
        bins = 40,
        edgecolor = 'black')
plt.title('Histogram of Predicted Housing Prices')
plt.xlabel('Predicted Housing Prices')
plt.ylabel('Frequency');

plt.savefig('./Graphs/Histogram of Predicted Housing Prices')


np.mean(predictions['saleprice'])


predictions.to_csv('./Predictions/filtered_data_predictions_3.csv')








df_train_filtered = pd.concat([df_train_filtered, df_train_filtered_dropped])


X = df_train_filtered.drop(columns = 'saleprice')
y = df_train_filtered['saleprice']

X['house_sf'] = np.log(X['house_sf'] + 1)
X['total_bsmt_sf'] = np.log(X['total_bsmt_sf'] + 1)  # +1 to handle zeros
X['wood_deck_sf'] = np.log(X['wood_deck_sf'] + 1)  # +1 to handle zeros
X['open_porch_sf'] = np.log(X['open_porch_sf'] + 1)  # +1 to handle zeros
X['garage_capacity'] = np.log(X['garage_capacity'] + 1)

df_test_filtered['house_sf'] = np.log(df_test_filtered['house_sf'] + 1)
df_test_filtered['garage_capacity'] = np.log(df_test_filtered['garage_capacity'] + 1)
df_test_filtered['total_bsmt_sf'] = np.log(df_test_filtered['total_bsmt_sf'] + 1)  # +1 to handle zeros
df_test_filtered['wood_deck_sf'] = np.log(df_test_filtered['wood_deck_sf'] + 1)  # +1 to handle zeros
df_test_filtered['open_porch_sf'] = np.log(df_test_filtered['open_porch_sf'] + 1)  # +1 to handle zeros

y = np.log(df_train_filtered['saleprice']) # transforming prices into a percent

X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42)
lr = LinearRegression()
lr.fit(X_train,y_train)

print(lr.score(X_train,y_train))
print(lr.score(X_test,y_test))


sc = StandardScaler()
Z_train = sc.fit_transform(X_train)
Z_test = sc.fit_transform(X_test)

r_alphas = np.logspace(0,5,100)

# Cross-validate over our list of ridge alphas.
ridge_cv = RidgeCV(alphas = r_alphas,
                  scoring = 'r2', # using r2 to determine what works best
                  cv = 5)# lets do 5 fold crossvalitaion

ridge_cv.fit(Z_train,y_train)
# Instantiate.
ridge_model = Ridge(alpha = ridge_cv.alpha_)

# Fit.
ridge_model.fit(Z_train,y_train)


# Evaluate model using R2.
print(ridge_model.score(Z_train,y_train))
print(ridge_model.score(Z_test,y_test))



y_pred = lr.predict(Z_test)
residuals = y_test - y_pred

# Create residual plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Sale Price')
plt.ylabel('Residuals')
plt.title('Residual Plot');


metrics.mean_squared_error(y_test,y_pred)


preds = ridge_model.predict(sc.transform(df_test_filtered))  # Use the same scaler on df_test_filtered
predictions = df_test_filtered.copy()
predictions['saleprice'] = np.exp(preds)  # Convert log-predictions back to the original scale
predictions = predictions[['saleprice']]
predictions.head()


plt.hist(predictions['saleprice'],
        bins = 40,
        edgecolor = 'black');


predictions.to_csv('./Predictions/filtered_data_predictions_4.csv')
# # this was terrible a score on kaggle.








plt.scatter(df_train_filtered['saleprice'],
           df_train_filtered['house_sf']);


# filter out the two outliers for large surface area to saleprice
df_train_filtered = df_train_filtered[df_train_filtered['house_sf'] <= 4000]


plt.scatter(df_train_filtered['saleprice'],
           df_train_filtered['house_sf']);


X = df_train_filtered.drop(columns = ['saleprice','garage_finish_none'])
y = df_train_filtered['saleprice']

X['house_sf'] = np.log(X['house_sf'] + 1)
X['total_bsmt_sf'] = np.log(X['total_bsmt_sf'] + 1)  # +1 to handle zeros
X['wood_deck_sf'] = np.log(X['wood_deck_sf'] + 1)  # +1 to handle zeros
X['open_porch_sf'] = np.log(X['open_porch_sf'] + 1)  # +1 to handle zeros
X['garage_capacity'] = np.log(X['garage_capacity'] + 1)

df_test_filtered['house_sf'] = np.log(df_test_filtered['house_sf'] + 1)
df_test_filtered['garage_capacity'] = np.log(df_test_filtered['garage_capacity'] + 1)
df_test_filtered['total_bsmt_sf'] = np.log(df_test_filtered['total_bsmt_sf'] + 1)  # +1 to handle zeros
df_test_filtered['wood_deck_sf'] = np.log(df_test_filtered['wood_deck_sf'] + 1)  # +1 to handle zeros
df_test_filtered['open_porch_sf'] = np.log(df_test_filtered['open_porch_sf'] + 1)  # +1 to handle zeros

df_test_filtered = df_test_filtered.drop(columns = 'garage_finish_none')

y = np.log(df_train_filtered['saleprice']) # transforming prices into a percent

X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42)
lr = LinearRegression()
lr.fit(X_train,y_train)

print(lr.score(X_train,y_train))
print(lr.score(X_test,y_test))


y_test = np.exp(y_test)

y_pred = lr.predict(X_test)
y_pred = np.exp(y_pred)
residuals = y_test - y_pred

# Create residual plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Sale Price')
plt.ylabel('Residuals')
plt.title('Residual Plot');


lr.fit(X,y)
preds = lr.predict(df_test_filtered)
predictions = df_test_filtered.copy()
# change those logs back to actual housing prices
predictions['saleprice'] = np.exp(preds)
predictions = predictions[['saleprice']]
predictions.head()


metrics.mean_squared_error(y_test,y_pred)


plt.hist(predictions['saleprice'],
        bins = 40,
        edgecolor = 'black')
plt.title('Histogram of Predicted Housing Prices')
plt.xlabel('Predicted Housing Prices')
plt.ylabel('Frequency');


np.mean(predictions['saleprice'])


predictions.to_csv('./Predictions/filtered_data_predictions_5.csv')








# Scatter plot of Actual vs. Predicted Sale Prices with adjusted limits
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)

# Calc min max values for actual and predicted for the line
min_val = min(y_test.min(), y_pred.min())
max_val = max(y_test.max(), y_pred.max())

# Make the 45 degree line
plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label="45-degree line")

plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')
plt.title('Actual vs. Predicted Sale Prices in USD');


# Select a few random sample indices from the test set
sample_indices = X_test.sample(10, random_state=42).index

# Extract sample data for actual values and features
sample_X = X_test.loc[sample_indices]
sample_y_actual = y_test.loc[sample_indices]

# Predict sale prices for these samples and convert back to original scale
sample_y_pred_log = lr.predict(sample_X)
sample_y_pred = np.exp(sample_y_pred_log)

# Calculate percentage error
percentage_error = ((sample_y_pred - sample_y_actual) / sample_y_actual) * 100

# Create a DataFrame to display the results
sample_results = pd.DataFrame({
    'House Square Footage': np.exp(sample_X['house_sf']),  # Convert log-transformed features if needed
    'Garage Capacity': np.exp(sample_X['garage_capacity']),
    'Total Basement SF': np.exp(sample_X['total_bsmt_sf']),
    'Age of House': sample_X['age'],
    'Years since Remodel': sample_X['years_since_remod'],
    'Actual Sale Price': sample_y_actual,
    'Predicted Sale Price': sample_y_pred,
    'Percentage Error': percentage_error
})

# Display the table
print(sample_results)


coefficients = lr.coef_
feature_names = X_train.columns

coef_dict = {feature: coef for feature, coef in zip(feature_names, coefficients)}

coef_df = pd.DataFrame(coef_dict.items(), columns=['Feature', 'Coefficient'])
coef_df = coef_df.sort_values(by='Coefficient', ascending=False)
print(coef_df)



